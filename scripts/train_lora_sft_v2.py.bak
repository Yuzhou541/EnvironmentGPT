import os, inspect, time, logging, sys
import torch
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForCausalLM

from peft import LoraConfig
from trl import SFTTrainer

# ---- logging: make sure things print even when piped to tee ----
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(name)s: %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)
log = logging.getLogger("train_lora_sft_v2")

def _filter_kwargs(callable_obj, kwargs: dict):
    sig = inspect.signature(callable_obj).parameters
    return {k: v for k, v in kwargs.items() if k in sig}

# ---- cfg ----
MODEL = os.environ.get("BASE_MODEL", "Qwen/Qwen2.5-7B-Instruct")
train_file = os.environ.get("TRAIN_FILE", "data/train/sft_train.jsonl")
eval_file  = os.environ.get("EVAL_FILE",  "data/train/sft_dev.jsonl")
out_dir    = os.environ.get("OUT_DIR",    "outputs/envgpt_qwen2p5_7b_lora")

max_seq_len = int(os.environ.get("MAX_SEQ_LEN", "2048"))
lr = float(os.environ.get("LR", "2e-4"))
epochs = float(os.environ.get("EPOCHS", "1"))
bsz = int(os.environ.get("BSZ", "1"))
gas = int(os.environ.get("GAS", "8"))
save_steps = int(os.environ.get("SAVE_STEPS", "500"))
eval_steps = int(os.environ.get("EVAL_STEPS", "500"))
logging_steps = int(os.environ.get("LOG_STEPS", "20"))

os.makedirs(out_dir, exist_ok=True)
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")

log.info(f"[cfg] model={MODEL}")
log.info(f"[cfg] train_file={train_file}")
log.info(f"[cfg] eval_file={eval_file}")
log.info(f"[cfg] out_dir={out_dir}")
log.info(f"[cfg] max_seq_len={max_seq_len} lr={lr} epochs={epochs} bsz={bsz} gas={gas}")

if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    log.info("[cfg] cuda available, TF32 enabled")

# ---- tokenizer/model ----
log.info("[init] loading tokenizer...")
tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

dtype = torch.bfloat16 if (torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8) else torch.float16
log.info(f"[cfg] torch_dtype={dtype}")

log.info("[init] loading model...")
model = AutoModelForCausalLM.from_pretrained(
    MODEL,
    trust_remote_code=True,
    torch_dtype=dtype,
    device_map="auto",
)
model.config.use_cache = False
model.gradient_checkpointing_enable()

# ---- LoRA ----
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules=["q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj","down_proj"],
)

# ---- dataset ----
log.info("[data] loading dataset jsonl...")
ds = load_dataset("json", data_files={"train": train_file, "eval": eval_file})
log.info(f"[data] train={len(ds['train'])} eval={len(ds['eval'])}")
log.info(f"[data] columns(train)={ds['train'].column_names}")

# TRL(你当前版本) 需要 prompt+completion 列；你的是 prompt+response
if "completion" not in ds["train"].column_names:
    if "response" in ds["train"].column_names:
        ds = ds.rename_column("response", "completion")
        log.info("[data] rename_column: response -> completion")
    else:
        raise ValueError("Dataset must contain either 'completion' or 'response' column.")

# 再次确认
need_cols = {"prompt", "completion"}
missing = need_cols - set(ds["train"].column_names)
if missing:
    raise ValueError(f"Dataset missing columns: {missing}. Current columns={ds['train'].column_names}")

# ---- args: prefer TRL's SFTConfig if available, otherwise fall back ----
try:
    from trl import SFTConfig
    ArgsCls = SFTConfig
    log.info("[cfg] using trl.SFTConfig")
except Exception:
    from transformers import TrainingArguments as ArgsCls
    log.info("[cfg] using transformers.TrainingArguments (fallback)")

args_kwargs = dict(
    output_dir=out_dir,
    per_device_train_batch_size=bsz,
    per_device_eval_batch_size=1,
    gradient_accumulation_steps=gas,
    learning_rate=lr,
    num_train_epochs=epochs,
    max_grad_norm=1.0,

    # IMPORTANT: new Transformers/TRL uses eval_strategy (not evaluation_strategy)
    eval_strategy="steps",
    eval_steps=eval_steps,

    save_strategy="steps",
    save_steps=save_steps,
    save_total_limit=2,

    logging_strategy="steps",
    logging_steps=logging_steps,
    logging_first_step=True,

    report_to="none",
    bf16=(dtype == torch.bfloat16),
    fp16=(dtype == torch.float16),

    # SFT-specific (exists in SFTConfig)
    max_length=max_seq_len,
    packing=False,
    completion_only_loss=True,
)

training_args = ArgsCls(**_filter_kwargs(ArgsCls, args_kwargs))
log.info("[train] args built OK")

# ---- build trainer with API-compat handling ----
trainer_kwargs = dict(
    model=model,
    args=training_args,
    train_dataset=ds["train"],
    eval_dataset=ds["eval"],
    peft_config=lora_config,
)

# TRL 新版叫 processing_class=tokenizer；旧版叫 tokenizer=tokenizer
sig = inspect.signature(SFTTrainer.__init__).parameters
if "processing_class" in sig:
    trainer_kwargs["processing_class"] = tokenizer
elif "tokenizer" in sig:
    trainer_kwargs["tokenizer"] = tokenizer
else:
    raise RuntimeError("SFTTrainer init signature has neither processing_class nor tokenizer.")

log.info("[train] building trainer...")
trainer = SFTTrainer(**trainer_kwargs)

log.info("[train] start training...")
t0 = time.time()
trainer.train()
dt = time.time() - t0
log.info(f"[done] training finished in {dt/60:.1f} min")

log.info("[save] saving adapter + tokenizer...")
trainer.model.save_pretrained(out_dir)
tokenizer.save_pretrained(out_dir)
log.info(f"[done] saved -> {out_dir}")
